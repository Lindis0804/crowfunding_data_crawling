{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment this line if you want to install package\n",
    "#pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium.common.exceptions\n",
    "import urllib3.exceptions\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from time import sleep\n",
    "import threading\n",
    "import csv\n",
    "import traceback\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['hi', 2, 3], [4, 5]]\n",
      "[1, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "def split_list(lst, k):\n",
    "    \"\"\"\n",
    "    This function is used to split a list to sub-lists that have k items.\n",
    "\n",
    "    Args:\n",
    "        lst (list): input list\n",
    "        k (int): number of item of a sub-list\n",
    "\n",
    "    Returns:\n",
    "        list: list of sub-list\n",
    "    For example:\n",
    "    split_list([1,2,3,4,5],2) => [[1,2],[3,4],[5]]\n",
    "    \"\"\"\n",
    "    size = len(lst)\n",
    "    return [lst[i:i+k] for i in range(0, size, k)]\n",
    "\n",
    "\n",
    "print(split_list([\"hi\", 2, 3, 4, 5], 3))\n",
    "print([1,2,3,4,5,6][:-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "def get_first_not_null_item(lsts):\n",
    "    \"\"\"\n",
    "      this function is used to get the first not null item of a list, it there is no not-null item,\n",
    "      this func returns the last item\n",
    "      \n",
    "    Args:\n",
    "        lsts (list): input list\n",
    "\n",
    "    Returns:\n",
    "        string: the first not null item\n",
    "    \"\"\"\n",
    "    for l in lsts:\n",
    "        if (len(l)!=0):\n",
    "            return l\n",
    "    return lsts[-1]\n",
    "print(get_first_not_null_item(['','1','']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_detail_project(page, url,error_url_file):\n",
    "    \"\"\"\n",
    "    This func is used to crawl data of a detail project page of Kickstarter website\n",
    "\n",
    "    Args:\n",
    "        page (int): page index of url\n",
    "        url (string): link to website that need to be crawled\n",
    "        error_url_file (string): name of file that contains a list of error urls that can not be crawled (\n",
    "            this list will be executed later\n",
    "        )\n",
    "    \"\"\"\n",
    "    browser = webdriver.Chrome(\n",
    "        service=(Service(ChromeDriverManager().install()))\n",
    "    )\n",
    "    try:\n",
    "        print(\"crawl url: \")\n",
    "        print(url)\n",
    "        browser.get(url)\n",
    "        # sleep(2)\n",
    "        # t = title.text\n",
    "        wait = WebDriverWait(browser, 10)\n",
    "        # title = wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR,'h2.type-28.type-24-md.soft-black.mb1.project-name')))\n",
    "        title = get_first_not_null_item(list(map(lambda a:a.text,browser.find_elements(\n",
    "            By.CSS_SELECTOR, \"h2.type-24-md.soft-black.mb1.project-name\"))))\n",
    "        description = get_first_not_null_item(list(map(lambda a:a.text,browser.find_elements(\n",
    "            By.CSS_SELECTOR, \"p[class='type-14 type-18-md soft-black project-description mb1']\"))))\n",
    "        picture = browser.find_element(\n",
    "            By.CSS_SELECTOR, \"img[class='aspect-ratio--object bg-black z3']\").get_attribute(\"src\")\n",
    "        pledged = get_first_not_null_item(list(map(lambda a:a.text,browser.find_elements(\n",
    "            By.CSS_SELECTOR, \"span[class='ksr-green-500']\"))))\n",
    "        # goal = get_first_not_null_item(list(map(lambda a:a.text,browser.find_elements(By.CSS_SELECTOR, \"span[class='inline-block-sm hide']\")[\n",
    "        #     1].find_element(By.CSS_SELECTOR, \"span[class='money']\"))))\n",
    "        span_goal = browser.find_elements(By.CSS_SELECTOR, \"span[class='inline-block-sm hide']\")\n",
    "        n_goal = []\n",
    "        for i in span_goal:\n",
    "            goals = i.find_elements(By.CSS_SELECTOR, \"span[class='money']\")\n",
    "            for goal in goals:\n",
    "                n_goal.append(goal.text)\n",
    "        goal = get_first_not_null_item(n_goal)\n",
    "        backers = get_first_not_null_item(list(map(lambda a:a.text,browser.find_elements(\n",
    "            By.CSS_SELECTOR, \"div[class='block type-16 type-28-md bold dark-grey-500']\"))))\n",
    "        days_to_go = get_first_not_null_item(list(map(lambda a:a.text,browser.find_elements(\n",
    "            By.CSS_SELECTOR, \"span[class='block type-16 type-28-md bold dark-grey-500']\"))))\n",
    "        file = open(\"./data/result.txt\",\"a\")\n",
    "        file.write(url+\"\\n\")\n",
    "        file.write(str([title, description, picture, pledged, goal, backers, days_to_go])+\"\\n\")\n",
    "        file.close()\n",
    "    except:\n",
    "        error_url = str(page)+\",\"+url+\"\\n\"\n",
    "        error_url_file_obj = open(error_url_file, \"a\")\n",
    "        error_url_file_obj.write(error_url)\n",
    "        error_url_file_obj.close()\n",
    "        traceback.print_exc()\n",
    "    browser.close()\n",
    "# get_data(current_page=current_page)\n",
    "#get_detail_project(0,\"https://www.kickstarter.com/projects/mlspencer/dragon-mage-deluxe-collectors-edition-hardcover\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(url,current_page,num_of_thread,error_url_file,checkpoint_file):\n",
    "    \"\"\"\n",
    "    This func is used to crawl data from Kickstarter website (\n",
    "        https://www.kickstarter.com/discover/advanced?woe_id=0&sort=magic&seed=2811224&page=\n",
    "    )\n",
    "\n",
    "    Args:\n",
    "        url (string): link to website\n",
    "        current_page (int): current page index of page that is being crawled\n",
    "        num_of_thread (int): num of crawling thread \n",
    "        error_url_file (string): name of file that contains a list of error_url_file that can not be crawled\n",
    "        checkpoint_file (string): name of file that contains information about the index of page that is being crawled\n",
    "    \"\"\"\n",
    "    page = current_page\n",
    "    while (1):\n",
    "        browser = webdriver.Chrome(\n",
    "        service=(Service(ChromeDriverManager().install()))\n",
    "    )\n",
    "        meta_url = url+str(page)\n",
    "        print(\"meta_url: \")\n",
    "        print(meta_url)\n",
    "        try:\n",
    "            browser.get(meta_url)\n",
    "            sleep(2)\n",
    "            links = list(map(lambda a: a.get_attribute(\"href\"),\n",
    "                                 browser.find_elements(By.CSS_SELECTOR,\n",
    "                                                       \"a[class='block img-placeholder w100p']\")\n",
    "                                 ))\n",
    "            prj_links = [l for l in links if l.endswith(\"?ref=discovery\")]\n",
    "            print(\"prj_links: \")\n",
    "            for l in prj_links:\n",
    "                print(l)\n",
    "            print(len(prj_links))\n",
    "            threads = []\n",
    "            split_prj_links = split_list(prj_links, num_of_thread)\n",
    "            last_prj_links = split_prj_links[-1]\n",
    "            print(\"split_prj_links: \")\n",
    "            print(split_prj_links)\n",
    "            for links in split_prj_links[:-1]:\n",
    "                threads = [threading.Thread(\n",
    "                        target=get_detail_project, args=(current_page, link,error_url_file)) for link in links]\n",
    "                for thread in threads:\n",
    "                    thread.start()\n",
    "                for thread in threads:\n",
    "                    thread.join()\n",
    "                threads = []\n",
    "            threads = [threading.Thread(\n",
    "                    target=get_detail_project, args=(current_page, link,error_url_file)) for link in last_prj_links]\n",
    "            for thread in threads:\n",
    "                thread.start()\n",
    "            for thread in threads:\n",
    "                thread.join()\n",
    "            threads = []\n",
    "            page = page+1\n",
    "        except:\n",
    "            file = open(checkpoint_file, \"w\")\n",
    "            file.write(str({\"page\": page}))\n",
    "            traceback.print_exc()\n",
    "            break\n",
    "        browser.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "meta_url: \n",
      "https://www.kickstarter.com/discover/advanced?woe_id=0&sort=magic&seed=2811224&page=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"e:\\software\\anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"e:\\software\\anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"e:\\software\\anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"e:\\software\\anaconda\\lib\\http\\client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"e:\\software\\anaconda\\lib\\http\\client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"e:\\software\\anaconda\\lib\\http\\client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"e:\\software\\anaconda\\lib\\socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\use\\AppData\\Local\\Temp\\ipykernel_21588\\378148493.py\", line 23, in get_data\n",
      "    browser.get(meta_url)\n",
      "  File \"e:\\software\\anaconda\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\", line 355, in get\n",
      "    self.execute(Command.GET, {\"url\": url})\n",
      "  File \"e:\\software\\anaconda\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\", line 344, in execute\n",
      "    response = self.command_executor.execute(driver_command, params)\n",
      "  File \"e:\\software\\anaconda\\lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py\", line 290, in execute\n",
      "    return self._request(command_info[0], url, body=data)\n",
      "  File \"e:\\software\\anaconda\\lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py\", line 311, in _request\n",
      "    response = self._conn.request(method, url, body=body, headers=headers)\n",
      "  File \"e:\\software\\anaconda\\lib\\site-packages\\urllib3\\request.py\", line 78, in request\n",
      "    return self.request_encode_body(\n",
      "  File \"e:\\software\\anaconda\\lib\\site-packages\\urllib3\\request.py\", line 170, in request_encode_body\n",
      "    return self.urlopen(method, url, **extra_kw)\n",
      "  File \"e:\\software\\anaconda\\lib\\site-packages\\urllib3\\poolmanager.py\", line 376, in urlopen\n",
      "    response = conn.urlopen(method, u.request_uri, **kw)\n",
      "  File \"e:\\software\\anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 787, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"e:\\software\\anaconda\\lib\\site-packages\\urllib3\\util\\retry.py\", line 550, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"e:\\software\\anaconda\\lib\\site-packages\\urllib3\\packages\\six.py\", line 769, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"e:\\software\\anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"e:\\software\\anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"e:\\software\\anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"e:\\software\\anaconda\\lib\\http\\client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"e:\\software\\anaconda\\lib\\http\\client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"e:\\software\\anaconda\\lib\\http\\client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"e:\\software\\anaconda\\lib\\socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))\n"
     ]
    }
   ],
   "source": [
    "# link to the website Kickstarter\n",
    "url = 'https://www.kickstarter.com/discover/advanced?woe_id=0&sort=magic&seed=2811224&page='\n",
    "\n",
    "# get the current page\n",
    "checkpoint = eval(open('./data/checkpoint.csv', \"r\").readline())\n",
    "current_page = checkpoint[\"page\"]\n",
    "error_url_file = 'error_url.csv'\n",
    "print(current_page)\n",
    "\n",
    "# start to crawl\n",
    "chrome_options = Options()\n",
    "chrome_options.add_experimental_option('detach',True)\n",
    "get_data(current_page=current_page,url=url,num_of_thread=4,checkpoint_file=\"./data/checkpoint.csv\",error_url_file=\"./data/error_url.csv\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test some function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geats\n"
     ]
    }
   ],
   "source": [
    "print(\"geats\")\n",
    "browser = webdriver.Chrome(\n",
    "        service=(Service(ChromeDriverManager().install()))\n",
    "    )\n",
    "meta_url = url+str(4)\n",
    "browser.get(meta_url)\n",
    "sleep(1)\n",
    "browser.close()\n",
    "browser = webdriver.Chrome(\n",
    "        service=(Service(ChromeDriverManager().install()))\n",
    "    )\n",
    "browser.get(url+str(5))\n",
    "sleep(1)\n",
    "# get_data(current_page=current_page)\n",
    "# get_detail_project(0,\"https://www.kickstarter.com/projects/mlspencer/dragon-mage-deluxe-collectors-edition-hardcover\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "0\n",
      "[100, 2, 4]\n",
      "multi thread\n",
      "10000\n",
      "multi thread\n",
      "4\n",
      "multi thread\n",
      "9\n",
      "multi thread\n",
      "16\n",
      "multi thread\n",
      "25\n",
      "multi thread\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "# f = open(file,\"a\")\n",
    "# f.writelines(\"hello\")\n",
    "# f.writelines(\"hi\")\n",
    "# f.close()\n",
    "# f = open(file,\"r\")\n",
    "# l = list(map(lambda a:a.strip().split(\",\"),f.readlines()))\n",
    "# print(l)\n",
    "print(\"hello\")\n",
    "x = ''\n",
    "print(len(x))\n",
    "def task(x):\n",
    "    print(\"multi thread\")\n",
    "    print(x * x)\n",
    "data = [[1,2],[2,3],[4,5]]\n",
    "inputs = [100,2,3,4,5,7]\n",
    "\n",
    "res = [i for i in inputs if i % 2==0]\n",
    "print(res)\n",
    "threads =[]\n",
    "# for m in inputs:\n",
    "#     thread = threading.Thread(target=task,args=[m])\n",
    "#     threads.append(thread)\n",
    "threads = [threading.Thread(target=task,args=[m]) for m in inputs]\n",
    "for thread in threads:\n",
    "    thread.start()\n",
    "    thread.join()\n",
    "# pool.close()\n",
    "#pool.join()\n",
    "#print(\"results: {}\".format(results))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello world\")\n",
    "for i in range(0, 5):\n",
    "    print(i)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
