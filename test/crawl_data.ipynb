{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in e:\\software\\anaconda\\lib\\site-packages (from -r requirements.txt (line 1)) (4.10.0)\n",
      "Requirement already satisfied: webdriver_manager in e:\\software\\anaconda\\lib\\site-packages (from -r requirements.txt (line 2)) (3.8.6)\n",
      "Requirement already satisfied: pymongo in e:\\software\\anaconda\\lib\\site-packages (from -r requirements.txt (line 3)) (4.3.3)\n",
      "Requirement already satisfied: requests in e:\\software\\anaconda\\lib\\site-packages (from -r requirements.txt (line 4)) (2.28.1)\n",
      "Requirement already satisfied: urllib3 in e:\\software\\anaconda\\lib\\site-packages (from -r requirements.txt (line 5)) (1.26.11)\n",
      "Requirement already satisfied: fastapi in e:\\software\\anaconda\\lib\\site-packages (from -r requirements.txt (line 6)) (0.97.0)\n",
      "Requirement already satisfied: kafka in e:\\software\\anaconda\\lib\\site-packages (from -r requirements.txt (line 7)) (1.3.5)\n",
      "Requirement already satisfied: confluent_kafka in e:\\software\\anaconda\\lib\\site-packages (from -r requirements.txt (line 8)) (2.1.1)\n",
      "Collecting kafka-python\n",
      "  Using cached kafka_python-2.0.2-py2.py3-none-any.whl (246 kB)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in e:\\software\\anaconda\\lib\\site-packages (from selenium->-r requirements.txt (line 1)) (2022.9.14)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in e:\\software\\anaconda\\lib\\site-packages (from selenium->-r requirements.txt (line 1)) (0.10.3)\n",
      "Requirement already satisfied: trio~=0.17 in e:\\software\\anaconda\\lib\\site-packages (from selenium->-r requirements.txt (line 1)) (0.22.0)\n",
      "Requirement already satisfied: python-dotenv in e:\\software\\anaconda\\lib\\site-packages (from webdriver_manager->-r requirements.txt (line 2)) (1.0.0)\n",
      "Requirement already satisfied: tqdm in e:\\software\\anaconda\\lib\\site-packages (from webdriver_manager->-r requirements.txt (line 2)) (4.64.1)\n",
      "Requirement already satisfied: packaging in e:\\software\\anaconda\\lib\\site-packages (from webdriver_manager->-r requirements.txt (line 2)) (21.3)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in e:\\software\\anaconda\\lib\\site-packages (from pymongo->-r requirements.txt (line 3)) (2.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\software\\anaconda\\lib\\site-packages (from requests->-r requirements.txt (line 4)) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in e:\\software\\anaconda\\lib\\site-packages (from requests->-r requirements.txt (line 4)) (2.0.4)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<2.0.0,>=1.7.4 in e:\\software\\anaconda\\lib\\site-packages (from fastapi->-r requirements.txt (line 6)) (1.10.9)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in e:\\software\\anaconda\\lib\\site-packages (from fastapi->-r requirements.txt (line 6)) (0.27.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in e:\\software\\anaconda\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<2.0.0,>=1.7.4->fastapi->-r requirements.txt (line 6)) (4.3.0)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in e:\\software\\anaconda\\lib\\site-packages (from starlette<0.28.0,>=0.27.0->fastapi->-r requirements.txt (line 6)) (3.5.0)\n",
      "Requirement already satisfied: cffi>=1.14 in e:\\software\\anaconda\\lib\\site-packages (from trio~=0.17->selenium->-r requirements.txt (line 1)) (1.15.1)\n",
      "Requirement already satisfied: async-generator>=1.9 in e:\\software\\anaconda\\lib\\site-packages (from trio~=0.17->selenium->-r requirements.txt (line 1)) (1.10)\n",
      "Requirement already satisfied: attrs>=19.2.0 in e:\\software\\anaconda\\lib\\site-packages (from trio~=0.17->selenium->-r requirements.txt (line 1)) (21.4.0)\n",
      "Requirement already satisfied: sniffio in e:\\software\\anaconda\\lib\\site-packages (from trio~=0.17->selenium->-r requirements.txt (line 1)) (1.2.0)\n",
      "Requirement already satisfied: sortedcontainers in e:\\software\\anaconda\\lib\\site-packages (from trio~=0.17->selenium->-r requirements.txt (line 1)) (2.4.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in e:\\software\\anaconda\\lib\\site-packages (from trio~=0.17->selenium->-r requirements.txt (line 1)) (1.1.1)\n",
      "Requirement already satisfied: outcome in e:\\software\\anaconda\\lib\\site-packages (from trio~=0.17->selenium->-r requirements.txt (line 1)) (1.2.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in e:\\software\\anaconda\\lib\\site-packages (from trio-websocket~=0.9->selenium->-r requirements.txt (line 1)) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in e:\\software\\anaconda\\lib\\site-packages (from urllib3->-r requirements.txt (line 5)) (1.7.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in e:\\software\\anaconda\\lib\\site-packages (from packaging->webdriver_manager->-r requirements.txt (line 2)) (3.0.9)\n",
      "Requirement already satisfied: colorama in e:\\software\\anaconda\\lib\\site-packages (from tqdm->webdriver_manager->-r requirements.txt (line 2)) (0.4.5)\n",
      "Requirement already satisfied: pycparser in e:\\software\\anaconda\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium->-r requirements.txt (line 1)) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in e:\\software\\anaconda\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium->-r requirements.txt (line 1)) (0.14.0)\n",
      "Installing collected packages: kafka-python\n",
      "Successfully installed kafka-python-2.0.2\n"
     ]
    }
   ],
   "source": [
    "#uncomment this line if you want to install package\n",
    "!pip install -r requirements.txt\n",
    "#!pip install fastapi\n",
    "#pip install --upgrade pip\n",
    "#print(\"Hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall confluent_kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'IncompatibleBrokerVersion' from 'kafka.errors' (e:\\software\\anaconda\\lib\\site-packages\\kafka\\errors.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7120\\208036786.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mfastapi\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFastAPI\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mn_kafka\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproducer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mProjectProducer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32me:\\Studying\\big_data\\project\\n_kafka\\producer.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkafka\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKafkaProducer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mProjectProducer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\software\\anaconda\\lib\\site-packages\\kafka\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkafka\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madmin\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKafkaAdminClient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkafka\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient_async\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKafkaClient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkafka\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconsumer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKafkaConsumer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\software\\anaconda\\lib\\site-packages\\kafka\\admin\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkafka\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madmin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig_resource\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mConfigResource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mConfigResourceType\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkafka\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madmin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKafkaAdminClient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m from kafka.admin.acl_resource import (ACL, ACLFilter, ResourcePattern, ResourcePatternFilter, ACLOperation,\n\u001b[0;32m      6\u001b[0m                                       ResourceType, ACLPermissionType, ACLResourcePatternType)\n",
      "\u001b[1;32me:\\software\\anaconda\\lib\\site-packages\\kafka\\admin\\client.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkafka\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoordinator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotocol\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mConsumerProtocolMemberMetadata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mConsumerProtocolMemberAssignment\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mConsumerProtocol\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkafka\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mErrors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m from kafka.errors import (\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mIncompatibleBrokerVersion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mKafkaConfigurationError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNotControllerError\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     UnrecognizedBrokerVersion, IllegalArgumentError)\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'IncompatibleBrokerVersion' from 'kafka.errors' (e:\\software\\anaconda\\lib\\site-packages\\kafka\\errors.py)"
     ]
    }
   ],
   "source": [
    "import selenium.common.exceptions\n",
    "import urllib3.exceptions\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from time import sleep\n",
    "import threading\n",
    "import csv\n",
    "import traceback\n",
    "import multiprocessing\n",
    "from typing import Union\n",
    "from fastapi import FastAPI\n",
    "import json\n",
    "from n_kafka.producer import ProjectProducer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['hi', 2, 3], [4, 5]]\n",
      "[1, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "def split_list(lst, k):\n",
    "    \"\"\"\n",
    "    This function is used to split a list to sub-lists that have k items.\n",
    "\n",
    "    Args:\n",
    "        lst (list): input list\n",
    "        k (int): number of item of a sub-list\n",
    "\n",
    "    Returns:\n",
    "        list: list of sub-list\n",
    "    For example:\n",
    "    split_list([1,2,3,4,5],2) => [[1,2],[3,4],[5]]\n",
    "    \"\"\"\n",
    "    size = len(lst)\n",
    "    return [lst[i:i+k] for i in range(0, size, k)]\n",
    "\n",
    "\n",
    "print(split_list([\"hi\", 2, 3, 4, 5], 3))\n",
    "print([1,2,3,4,5,6][:-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "def get_first_not_null_item(lsts):\n",
    "    \"\"\"\n",
    "      this function is used to get the first not null item of a list, it there is no not-null item,\n",
    "      this func returns the last item\n",
    "      \n",
    "    Args:\n",
    "        lsts (list): input list\n",
    "\n",
    "    Returns:\n",
    "        string: the first not null item\n",
    "    \"\"\"\n",
    "    for l in lsts:\n",
    "        if (len(l)!=0):\n",
    "            return l\n",
    "    return lsts[-1]\n",
    "print(get_first_not_null_item(['','1','']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crawl url: \n",
      "https://www.kickstarter.com/projects/mlspencer/dragon-mage-deluxe-collectors-edition-hardcover\n",
      "[*] Sending to broker localhost:9092, topic: kickstarter_project\n",
      "b'{\"title\": \"Dragon Mage: Deluxe Collector\\'s Edition Hardcover\", \"description\": \"A deluxe, signed, faux-leather Collector\\'s Edition of the first book in the multi-award-winning epic fantasy series Rivenworld.\", \"picture\": \"https://ksr-ugc.imgix.net/assets/041/284/528/eaed1a1d708b34bbc525d42fe063f646_original.png?ixlib=rb-4.0.2&crop=faces&w=1024&h=576&fit=crop&v=1686684665&auto=format&frame=1&q=92&s=2a9491a0399da60e0010d30f6dde643d\", \"pledged\": \"US$ 60,607\", \"goal\": \"US$ 14,000\", \"num_of_backer\": \"507\", \"days_to_go\": \"14\", \"mark\": \"Project We Love\", \"field\": \"Fiction\", \"location\": \"Redlands, CA\", \"num_of_comment\": \"55\"}'\n",
      "Send message synchronously\n",
      "Message delivery failed: KafkaError{code=_MSG_TIMED_OUT,val=-192,str=\"Local: Message timed out\"}\n",
      "[*] Send to kafka successfully.\n"
     ]
    }
   ],
   "source": [
    "def get_detail_project(page, url,error_url_file,producer_info=[]):\n",
    "    \"\"\"\n",
    "    This func is used to crawl data of a detail project page of Kickstarter website\n",
    "\n",
    "    Args:\n",
    "        page (int): page index of url\n",
    "        url (string): link to website that need to be crawled\n",
    "        error_url_file (string): name of file that contains a list of error urls that can not be crawled (\n",
    "            this list will be executed later\n",
    "        )\n",
    "    \"\"\"\n",
    "    browser = webdriver.Chrome(\n",
    "        service=(Service(ChromeDriverManager().install()))\n",
    "    )\n",
    "    try:\n",
    "        print(\"crawl url: \")\n",
    "        print(url)\n",
    "        browser.get(url)\n",
    "        # sleep(2)\n",
    "        # t = title.text\n",
    "        wait = WebDriverWait(browser, 10)\n",
    "        title = get_first_not_null_item(list(map(lambda a:a.text,browser.find_elements(\n",
    "            By.CSS_SELECTOR, \"h2.type-24-md.soft-black.mb1.project-name\"))))\n",
    "        description = get_first_not_null_item(list(map(lambda a:a.text,browser.find_elements(\n",
    "            By.CSS_SELECTOR, \"p[class='type-14 type-18-md soft-black project-description mb1']\"))))\n",
    "        picture = browser.find_element(\n",
    "            By.CSS_SELECTOR, \"img[class='aspect-ratio--object bg-black z3']\").get_attribute(\"src\")\n",
    "        pledged = get_first_not_null_item(list(map(lambda a:a.text,browser.find_elements(\n",
    "            By.CSS_SELECTOR, \"span[class='ksr-green-500']\"))))\n",
    "        span_goal = browser.find_elements(By.CSS_SELECTOR, \"span[class='inline-block-sm hide']\")\n",
    "        n_goal = []\n",
    "        for i in span_goal:\n",
    "            goals = i.find_elements(By.CSS_SELECTOR, \"span[class='money']\")\n",
    "            for goal in goals:\n",
    "                n_goal.append(goal.text)\n",
    "        goal = get_first_not_null_item(n_goal)\n",
    "        num_of_backer = get_first_not_null_item(list(map(lambda a:a.text,browser.find_elements(\n",
    "            By.CSS_SELECTOR, \"div[class='block type-16 type-28-md bold dark-grey-500']\"))))\n",
    "        days_to_go = get_first_not_null_item(list(map(lambda a:a.text,browser.find_elements(\n",
    "            By.CSS_SELECTOR, \"span[class='block type-16 type-28-md bold dark-grey-500']\"))))\n",
    "        mark_field_locations = list(map(lambda a:a.text,browser.find_elements(\n",
    "            By.CSS_SELECTOR,\"a.nowrap.navy-700.flex.items-center.medium.mr3.type-12.keyboard-focusable > span.ml1\"\n",
    "        )))\n",
    "        mark = mark_field_locations[3]\n",
    "        field = mark_field_locations[4]\n",
    "        location = mark_field_locations[5]\n",
    "        num_of_comment = get_first_not_null_item(list(map(lambda a:a.text,browser.find_elements(\n",
    "            By.CSS_SELECTOR,\n",
    "            \"a.js-analytics-section.js-load-project-comments.js-load-project-content.mx3.project-nav__link--comments.tabbed-nav__link.type-14 > span.count\"\n",
    "        ))))\n",
    "        res = {\n",
    "            \"title\":title,\n",
    "            \"description\":description,\n",
    "            \"picture\":picture,\n",
    "            \"pledged\":pledged,\n",
    "            \"goal\":goal,\n",
    "            \"num_of_backer\":num_of_backer,\n",
    "            \"days_to_go\":days_to_go,\n",
    "            \"mark\":mark,\n",
    "            \"field\":field,\n",
    "            \"location\":location,\n",
    "            \"num_of_comment\":num_of_comment\n",
    "        }\n",
    "        if (len(producer_info)>0):\n",
    "            broker,topic = producer_info\n",
    "            print(\"[*] Sending to broker \"+broker+\", topic: \"+topic)\n",
    "            print(json.dumps(res).encode(\"utf-8\"))\n",
    "            projectProducer = ProjectProducer(broker=broker)\n",
    "            try:\n",
    "                projectProducer.send_msg_sync(json.dumps(res).encode(\"utf-8\"), topic=topic)\n",
    "                print(\"[*] Send to kafka successfully.\")\n",
    "            except:\n",
    "                print(\"[*] Send to kafka fail.\") \n",
    "        else:\n",
    "        #  file = open(\"./data/result.txt\",\"a\")\n",
    "        #  file.write(url+\"\\n\")\n",
    "        #  file.write(str(res)+\"\\n\")\n",
    "        #  file.close()\n",
    "          print(\"[*] Save data to mongodb.\")\n",
    "    except:\n",
    "        error_url = str(page)+\",\"+url+\"\\n\"\n",
    "        error_url_file_obj = open(error_url_file, \"a\")\n",
    "        error_url_file_obj.write(error_url)\n",
    "        error_url_file_obj.close()\n",
    "        traceback.print_exc()\n",
    "    browser.close()\n",
    "# get_data(current_page=current_page)\n",
    "get_detail_project(0,\"https://www.kickstarter.com/projects/mlspencer/dragon-mage-deluxe-collectors-edition-hardcover\",error_url_file=\"./data/error_url.csv\",producer_info=[\"localhost:9092\",\"kickstarter_project\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Sending to broker 127.0.0.1:9092, topic: kickstarter_project\n",
      "Oh my gosh.\n",
      "Send message synchronously\n",
      "Message delivery failed: KafkaError{code=_MSG_TIMED_OUT,val=-192,str=\"Local: Message timed out\"}\n",
      "[*] Send to kafka successfully.\n"
     ]
    }
   ],
   "source": [
    "broker,topic = \"localhost:9092\",\"kickstarter_project\"\n",
    "print(\"[*] Sending to broker \"+broker+\", topic: \"+topic)\n",
    "msg = \"Oh my gosh.\"\n",
    "print(msg)\n",
    "projectProducer = ProjectProducer(broker=broker)\n",
    "try:\n",
    "    projectProducer.send_msg_sync(msg, topic=topic)\n",
    "    print(\"[*] Send to kafka successfully.\")\n",
    "except:\n",
    "    print(\"[*] Send to kafka fail.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(url,current_page,num_of_thread,error_url_file,checkpoint_file):\n",
    "    \"\"\"\n",
    "    This func is used to crawl data from Kickstarter website (\n",
    "        https://www.kickstarter.com/discover/advanced?woe_id=0&sort=magic&seed=2811224&page=\n",
    "    )\n",
    "\n",
    "    Args:\n",
    "        url (string): link to website\n",
    "        current_page (int): current page index of page that is being crawled\n",
    "        num_of_thread (int): num of crawling thread \n",
    "        error_url_file (string): name of file that contains a list of error_url_file that can not be crawled\n",
    "        checkpoint_file (string): name of file that contains information about the index of page that is being crawled\n",
    "    \"\"\"\n",
    "    page = current_page\n",
    "    while (1):\n",
    "        browser = webdriver.Chrome(\n",
    "        service=(Service(ChromeDriverManager().install()))\n",
    "    )\n",
    "        meta_url = url+str(page)\n",
    "        print(\"meta_url: \")\n",
    "        print(meta_url)\n",
    "        try:\n",
    "            browser.get(meta_url)\n",
    "            sleep(2)\n",
    "            links = list(map(lambda a: a.get_attribute(\"href\"),\n",
    "                                 browser.find_elements(By.CSS_SELECTOR,\n",
    "                                                       \"a[class='block img-placeholder w100p']\")\n",
    "                                 ))\n",
    "            prj_links = [l for l in links if l.endswith(\"?ref=discovery\")]\n",
    "            print(\"prj_links: \")\n",
    "            for l in prj_links:\n",
    "                print(l)\n",
    "            print(len(prj_links))\n",
    "            threads = []\n",
    "            split_prj_links = split_list(prj_links, num_of_thread)\n",
    "            last_prj_links = split_prj_links[-1]\n",
    "            print(\"split_prj_links: \")\n",
    "            print(split_prj_links)\n",
    "            for links in split_prj_links[:-1]:\n",
    "                threads = [threading.Thread(\n",
    "                        target=get_detail_project, args=(current_page, link,error_url_file)) for link in links]\n",
    "                for thread in threads:\n",
    "                    thread.start()\n",
    "                for thread in threads:\n",
    "                    thread.join()\n",
    "                threads = []\n",
    "            threads = [threading.Thread(\n",
    "                    target=get_detail_project, args=(current_page, link,error_url_file)) for link in last_prj_links]\n",
    "            for thread in threads:\n",
    "                thread.start()\n",
    "            for thread in threads:\n",
    "                thread.join()\n",
    "            threads = []\n",
    "            page = page+1\n",
    "        except:\n",
    "            file = open(checkpoint_file, \"w\")\n",
    "            file.write(str({\"page\": page}))\n",
    "            traceback.print_exc()\n",
    "            break\n",
    "        browser.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# link to the website Kickstarter\n",
    "url = 'https://www.kickstarter.com/discover/advanced?woe_id=0&sort=magic&seed=2811224&page='\n",
    "\n",
    "# get the current page\n",
    "checkpoint = eval(open('./data/checkpoint.csv', \"r\").readline())\n",
    "current_page = checkpoint[\"page\"]\n",
    "error_url_file = 'error_url.csv'\n",
    "print(current_page)\n",
    "\n",
    "# start to crawl\n",
    "app = FastAPI()\n",
    "chrome_options = Options()\n",
    "chrome_options.add_experimental_option('detach',True)\n",
    "@app.get(\"/projects\")\n",
    "def get_data_from_kickstarter(num_of_thread:int = 4):\n",
    " get_data(current_page=current_page,url=url,num_of_thread=num_of_thread,checkpoint_file=\"./data/checkpoint.csv\",error_url_file=\"./data/error_url.csv\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test some function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geats\n"
     ]
    }
   ],
   "source": [
    "print(\"geats\")\n",
    "browser = webdriver.Chrome(\n",
    "        service=(Service(ChromeDriverManager().install()))\n",
    "    )\n",
    "meta_url = url+str(4)\n",
    "browser.get(meta_url)\n",
    "sleep(1)\n",
    "browser.close()\n",
    "browser = webdriver.Chrome(\n",
    "        service=(Service(ChromeDriverManager().install()))\n",
    "    )\n",
    "browser.get(url+str(5))\n",
    "sleep(1)\n",
    "# get_data(current_page=current_page)\n",
    "# get_detail_project(0,\"https://www.kickstarter.com/projects/mlspencer/dragon-mage-deluxe-collectors-edition-hardcover\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "0\n",
      "[100, 2, 4]\n",
      "multi thread\n",
      "10000\n",
      "multi thread\n",
      "4\n",
      "multi thread\n",
      "9\n",
      "multi thread\n",
      "16\n",
      "multi thread\n",
      "25\n",
      "multi thread\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "# f = open(file,\"a\")\n",
    "# f.writelines(\"hello\")\n",
    "# f.writelines(\"hi\")\n",
    "# f.close()\n",
    "# f = open(file,\"r\")\n",
    "# l = list(map(lambda a:a.strip().split(\",\"),f.readlines()))\n",
    "# print(l)\n",
    "print(\"hello\")\n",
    "x = ''\n",
    "print(len(x))\n",
    "def task(x):\n",
    "    print(\"multi thread\")\n",
    "    print(x * x)\n",
    "data = [[1,2],[2,3],[4,5]]\n",
    "inputs = [100,2,3,4,5,7]\n",
    "\n",
    "res = [i for i in inputs if i % 2==0]\n",
    "print(res)\n",
    "threads =[]\n",
    "# for m in inputs:\n",
    "#     thread = threading.Thread(target=task,args=[m])\n",
    "#     threads.append(thread)\n",
    "threads = [threading.Thread(target=task,args=[m]) for m in inputs]\n",
    "for thread in threads:\n",
    "    thread.start()\n",
    "    thread.join()\n",
    "# pool.close()\n",
    "#pool.join()\n",
    "#print(\"results: {}\".format(results))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello world\")\n",
    "for i in range(0, 5):\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': 2}\n",
      "1 2 3\n"
     ]
    }
   ],
   "source": [
    "x = None\n",
    "y = {\n",
    "    \"x\": x if x is not None else 2\n",
    "}\n",
    "print(y)\n",
    "m = [1,2,3]\n",
    "a,b,c = m\n",
    "print(a,b,c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
